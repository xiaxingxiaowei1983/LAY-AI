import streamlit as st
import time

# æ¨¡æ‹Ÿåç«¯é€»è¾‘ä¸çŠ¶æ€æœº
class LayAI_Backend:
    def __init__(self):
        if "state" not in st.session_state:
            st.session_state.state = "IDLE" # åˆå§‹çŠ¶æ€
        if "history" not in st.session_state:
            st.session_state.history = []
    
    def get_response(self, user_input):
        # çŠ¶æ€æœºé€»è¾‘ (å¯¹åº” PRD 6.1)
        current_state = st.session_state.state
        
        # 1. IDLE -> DIAGNOSTIC (æ™ºå•†ç¨æµ‹è¯•å¯åŠ¨)
        if current_state == "IDLE":
            st.session_state.state = "DIAGNOSTIC_WAITING"
            return """
            (LAY æ­£åœ¨å®¡è§†ä½ çš„æŠ•èµ„è®¡åˆ’...)
            
            æˆ‘æ˜¯ LAYï¼Œä½ çš„é£æ§å‚è°‹ã€‚åœ¨è°ˆæŠ•èµ„ä¹‹å‰ï¼Œå…ˆçœ‹ä½ èƒ½ä¸èƒ½è¿‡è¿™å…³ã€‚
            
            **ã€æ™ºå•†ç¨æµ‹è¯•ã€‘**
            ä½ æ˜¯ä¸€ä¸ªå¤–è¡Œï¼Œæƒ³åœ¨äºŒçº¿åŸå¸‚è€åŸåŒºæ¥æ‰‹ä¸€å®¶çœ‹èµ·æ¥è£…ä¿®è¿˜å¯ä»¥çš„è½¬è®©åº—ã€‚æˆ¿ä¸œè¯´ï¼šâ€œè¿™åº—ä»¥å‰ç”Ÿæ„å¾ˆå¥½çš„ï¼Œæˆ‘å°±æ˜¯ç´¯äº†æƒ³ä¼‘æ¯ã€‚â€
            ä½ çš„ç¬¬ä¸€ååº”æ˜¯ï¼Ÿ
            
            A. æ¡æ¼äº†ï¼Œè£…ä¿®çœä¸€å¤§ç¬”é’±ï¼Œèµ¶ç´§ç­¾ã€‚
            B. è¦æ±‚çœ‹è¿‡å»ä¸‰å¹´çš„æµæ°´å’ŒOTAåå°æ•°æ®ã€‚
            C. è§‰å¾—æœ‰çŒ«è…»ï¼Œä½†ç›¸ä¿¡è‡ªå·±çš„è¿è¥èƒ½åŠ›èƒ½åšèµ·æ¥ã€‚
            
            (è¯·è¾“å…¥ A, B æˆ– C)
            """
            
        # 2. DIAGNOSTIC -> ANALYSIS (æµ‹è¯•åé¦ˆä¸åˆ†æ)
        elif current_state == "DIAGNOSTIC_WAITING":
            if user_input.upper() not in ["A", "B", "C"]:
                return "åˆ«æƒ³ç³Šå¼„è¿‡å»ã€‚é€‰ A, B è¿˜æ˜¯ Cï¼Ÿè¿™æ˜¯ä½ çš„çœŸé‡‘ç™½é“¶ã€‚"
            
            response = ""
            if user_input.upper() == "B":
                response = "**å‹‰å¼ºåŠæ ¼ã€‚** ä½†ä½ çŸ¥é“æµæ°´å¯ä»¥é€ å‡å—ï¼Ÿä½ çŸ¥é“OTAå·®è¯„å¯ä»¥è¢«â€œæŠ€æœ¯å¤„ç†â€å—ï¼Ÿä¸è¿‡ä½ è‡³å°‘æ²¡é‚£ä¹ˆå¤©çœŸã€‚\n\n"
            else:
                response = "**å…¸å‹éŸ­èœã€‚** é€‰Açš„æ˜¯ç»™æˆ¿ä¸œæ¥ç›˜è£…ä¿®åƒåœ¾çš„ï¼›é€‰Cçš„æ˜¯æ‚£äº†'è‡ªä¿¡å¹»è§‰ç—‡'çš„ã€‚è®°ä½ï¼šå¥½åº—ä¸éœ€è¦è½¬è®©ï¼Œè½¬è®©çš„éƒ½æ˜¯å‘ã€‚\n\n"
            
            st.session_state.state = "ANALYSIS"
            response += "æµ‹è¯•ç»“æŸã€‚ç°åœ¨å‘Šè¯‰æˆ‘ï¼Œ**ä½ æƒ³åœ¨å“ªä¸ªåŸå¸‚ï¼ŒæŠ•èµ„å¤šå°‘é’±ï¼Œåšä»€ä¹ˆç±»å‹çš„é…’åº—ï¼Ÿ** (ä¾‹å¦‚ï¼šæˆ‘æƒ³åœ¨é•¿æ²™å¼€ä¸€å®¶ä»¥ç”µç«ä¸ºä¸»é¢˜çš„é…’åº—ï¼Œé¢„ç®—200ä¸‡)"
            return response

        # 3. ANALYSIS -> GENERATING (åŸå¸‚è·¯ç”±ä¸ç”Ÿæˆ)
        elif current_state == "ANALYSIS":
            city = self.extract_city(user_input)
            tier = self.get_city_tier(city)
            
            template_type = "ã€ä¸€çº¿åŸå¸‚é«˜å‘¨è½¬æ¨¡æ¿ã€‘" if tier == "Tier1" else "ã€é€šç”¨ç”Ÿå­˜æ¨¡æ¿ã€‘"
            
            st.session_state.state = "GENERATING"
            
            return f"""
            æ”¶åˆ°ã€‚è¯†åˆ«åŸå¸‚ï¼š**{city}**
            åˆ¤å®šç­‰çº§ï¼š**{tier}** -> è°ƒç”¨ {template_type}
            
            æ­£åœ¨æ ¹æ®â€œæ™ºå•†ç¨ç ´å£æ¨¡å‹â€æ£€ç´¢ {city} çš„ç«å“æ•°æ®...
            æ­£åœ¨è°ƒç”¨â€œç³»ç»Ÿæ€§åºŸå¼ƒâ€æ¨¡å‹ä¼˜åŒ–æˆæœ¬ç»“æ„...
            
            --------------------------------
            **ã€Š{city}é…’åº—æŠ•èµ„åˆ†æåº•ç¨¿ (P1-P3)ã€‹**
            
            ### P1. å®è§‚ç¯å¢ƒä¸åŠé€€é¢„è­¦
            **ã€åç›´è§‰åˆ¤æ–­ã€‘**
            ä½ è®¤ä¸º{city}æ˜¯ç½‘çº¢åŸå¸‚ï¼Œæµé‡å¤§ï¼Ÿé”™äº†ã€‚
            æ ¹æ® {city} 2024å¹´æ–‡æ—…æ•°æ®ï¼Œè¿‡å¤œæ¸¸å®¢äººå‡æ¶ˆè´¹ä»…ä¸º...
            
            (æ­¤å¤„æ¨¡æ‹Ÿæµå¼è¾“å‡º 800å­—...)
            
            ...
            
            *(ç¯‡å¹…å·²è¾¾ä¸Šé™ï¼Œç³»ç»Ÿå·²æš‚åœã€‚è¯·è¾“å…¥â€œç»§ç»­â€æŸ¥çœ‹ P4 è´¢åŠ¡æµ‹ç®—è¡¨)*
            """
        
        # 4. PAUSED -> RESUMED (æ–­ç‚¹ç»­å†™)
        elif current_state == "GENERATING":
             return """
             ### P4. è´¢åŠ¡æµ‹ç®— (FMEAé£æ§ç‰ˆ)
             
             **ã€é£é™©å¯¹å†²åˆ†æã€‘**
             ä½ çš„å›æœ¬å‘¨æœŸæ¨¡å‹å»ºç«‹åœ¨å…¥ä½ç‡ 85% çš„å‡è®¾ä¸Šã€‚
             å¦‚æœä¸å¹¸é‡åˆ°ä¸å¯æŠ—åŠ›ï¼ˆå‚è€ƒ2020å¹´ï¼‰ï¼Œå…¥ä½ç‡è·Œè‡³ 40%ï¼Œä½ çš„ç°é‡‘æµèƒ½æ’‘å‡ ä¸ªæœˆï¼Ÿ
             
             ... (æ¨¡æ‹Ÿç”Ÿæˆ P4-P9) ...
             """
             
        return "ç³»ç»Ÿå¼‚å¸¸ï¼Œè¯·åˆ·æ–°ã€‚"

    # æ¨¡æ‹Ÿ PRD 4.2.2 çš„åŸå¸‚è·¯ç”±é€»è¾‘
    def extract_city(self, text):
        # ç®€å•æ¨¡æ‹Ÿå®ä½“æŠ½å–
        if "åŒ—äº¬" in text or "ä¸Šæµ·" in text: return "ä¸Šæµ·"
        if "é•¿æ²™" in text: return "é•¿æ²™"
        return "æœªçŸ¥åŸå¸‚"

    def get_city_tier(self, city):
        tier1 = ["åŒ—äº¬", "ä¸Šæµ·", "å¹¿å·", "æ·±åœ³"]
        if city in tier1: return "Tier1"
        return "General"

# --- Streamlit å‰ç«¯ç•Œé¢ ---

def main():
    st.set_page_config(page_title="LAY AI - é…’åº—æŠ•èµ„é£æ§å‚è°‹", layout="wide")

    # ä¾§è¾¹æ ï¼šé…ç½®ä¸å¯¼èˆª
    with st.sidebar:
        st.title("LAY AI v1.0")
        st.markdown("---")
        st.markdown("**å½“å‰æ¨¡å¼**: æŠ•èµ„é£æ§ (Risk Control)")
        st.markdown("**åŠ è½½æ¨¡å‹åº“**: 52ä¸ª (Active)")
        st.markdown("**æ•°æ®æº**: 2024 å®æ—¶è”ç½‘")
        st.markdown("---")
        st.info("ğŸ’¡ æç¤ºï¼šLAY è¯´è¯å¾ˆéš¾å¬ï¼Œä½†èƒ½å¸®ä½ çœå‡ ç™¾ä¸‡ã€‚")

    # ä¸»ç•Œé¢æ ‡é¢˜
    st.header("LAY AIï¼šæ‚¨çš„é…’åº—æŠ•èµ„é£æ§å‚è°‹")
    st.markdown("> *â€œåœ¨æŠ•å‰é˜¶æ®µè§„é¿æ¯ç­æ€§é£é™©ï¼Œè¾“å‡ºå¯è½åœ°çš„å±åœ°åŒ–æŠ•èµ„æ–¹æ¡ˆã€‚â€*")

    # åˆå§‹åŒ–åç«¯
    backend = LayAI_Backend()

    # èŠå¤©è®°å½•æ˜¾ç¤º
    for msg in st.session_state.history:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    # é¦–æ¬¡åŠ è½½è‡ªåŠ¨è§¦å‘ Hook (PRD 4.2.1)
    if not st.session_state.history:
        initial_msg = backend.get_response("")
        st.session_state.history.append({"role": "assistant", "content": initial_msg})
        st.rerun()

    # ç”¨æˆ·è¾“å…¥
    if prompt := st.chat_input("è¾“å…¥ä½ çš„æƒ³æ³•..."):
        # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
        st.session_state.history.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # æ˜¾ç¤º AI æ­£åœ¨æ€è€ƒ (æ¨¡æ‹Ÿ)
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            message_placeholder.markdown("*(LAY æ­£åœ¨è°ƒç”¨ 50+ æ¨¡å‹åº“è¿›è¡Œæ¼”ç®—...)*")
            time.sleep(1) # æ¨¡æ‹Ÿå»¶è¿Ÿ
            
            # è·å–åç«¯å›å¤
            full_response = backend.get_response(prompt)
            
            # æ¨¡æ‹Ÿæ‰“å­—æœºæ•ˆæœ
            displayed_response = ""
            for chunk in full_response.split():
                displayed_response += chunk + " "
                message_placeholder.markdown(displayed_response + "â–Œ")
                time.sleep(0.05)
            message_placeholder.markdown(full_response)
        
        # è®°å½• AI æ¶ˆæ¯
        st.session_state.history.append({"role": "assistant", "content": full_response})

if __name__ == "__main__":
    main()